
<!DOCTYPE HTML>
<html lang="zh" >
    <head>
        <meta charset="UTF-8">
        <title>第四章：数据导入和导出 · 大数据分析新玩法之Kusto宝典</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="HonKit 3.7.5">
        <meta name="author" content="陈希章">
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/@honkit/honkit-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
<!-- -->

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-PCF513CZTS"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
        dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', 'G-PCF513CZTS');
</script>
 
    </head>
    <body>
        
<div class="book honkit-cloak">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="輸入並搜尋" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../preface.html">
            
                <a href="../preface.html">
            
                    
                    作者自序
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="overview.html">
            
                <a href="overview.html">
            
                    
                    第一季：一元初始
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="chapter1.html">
            
                <a href="chapter1.html">
            
                    
                    第一章：Kusto简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="chapter2.html">
            
                <a href="chapter2.html">
            
                    
                    第二章：KQL核心
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="chapter3.html">
            
                <a href="chapter3.html">
            
                    
                    第三章：数据可视化
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.3.4" data-path="chapter4.html">
            
                <a href="chapter4.html">
            
                    
                    第四章：数据导入和导出
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="chapter5.html">
            
                <a href="chapter5.html">
            
                    
                    第五章：外部应用集成
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="chapter6.html">
            
                <a href="chapter6.html">
            
                    
                    第六章：自动化
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://github.com/honkit/honkit" target="blank" class="gitbook-link">
            本書使用 HonKit 釋出
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >第四章：数据导入和导出</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="第四章：数据导入和导出">第四章：数据导入和导出</h1>
<blockquote>
<p>作者：陈希章，2023年1月 于上海 
专栏：<strong>大数据分析新玩法之Kusto宝典</strong> 第一季：一元初始
反馈：<a href="mailto:ares@xizhang.com" target="_blank">ares@xizhang.com</a></p>
</blockquote>
<p>在前面的章节中，我们使用 <code>https://help.kusto.windows.net</code> 这个范例群集，以及主要使用了它内部的 <code>Samples</code> 这个数据库进行查询和分析。</p>
<p>那么，现在是时候来创建自己的群集，数据库，并且按照自己的需要来导入和导出数据了，只有完成了这一步，你才能较为全面地掌握Kusto（或者叫Azure Data Explorer）的能力。</p>
<p>如果你希望在生产环境使用 ADE， 你需要有Microsoft Azure的订阅，然后通过 <a href="https://portal.azure.com/#create/Microsoft.AzureKusto" target="_blank">https://portal.azure.com/#create/Microsoft.AzureKusto</a> 来创建，它的收费方式，请参考 <a href="https://azure.microsoft.com/en-us/pricing/details/data-explorer/" target="_blank">https://azure.microsoft.com/en-us/pricing/details/data-explorer/</a> 的详情。</p>
<p>但是，如果你只是用来研究和学习，则完全可以从免费的群集开始。</p>
<h2 id="创建免费群集">创建免费群集</h2>
<p>为了创建免费群集，你可以访问 <a href="https://aka.ms/kustofree" target="_blank">https://aka.ms/kustofree</a> 或者 <a href="https://dataexplorer.azure.com/freecluster" target="_blank">https://dataexplorer.azure.com/freecluster</a>。</p>
<p><img src="../images/Pasted%20image%2020230102222124.png" alt></p>
<p>输入你想要的群集显示名称，数据库名称和位置，然后完成登录操作后，你就可以拥有自己专属的群集了。你可以用 Microsoft 个人账号，或者工作账号登录。</p>
<p><img src="../images/Pasted%20image%2020230102221955.png" alt></p>
<p>每个群集都会有一个唯一的地址，作为免费群集，你不可以修改这个地址。而即便是免费版本，你也拥有了相当不错的配置。</p>
<p><img src="../images/Pasted%20image%2020230102221540.png" alt></p>
<p>当然，它跟正式版肯定会有所差异，请通过下表了解。</p>
<p><img src="../images/Pasted%20image%2020230102221421.png" alt></p>
<h2 id="创建数据库">创建数据库</h2>
<p>正如你所看到的，免费群集中允许最多10个数据库。创建数据库是很简单的，你还是可以通过 <a href="https://aka.ms/kustofree" target="_blank">https://aka.ms/kustofree</a> 进入控制面板，然后点击 ”Create database “ 即可。</p>
<p><img src="../images/Pasted%20image%2020230102222815.png" alt></p>
<p>为了便于一起做练习，请确保你创建了一个数据库叫 ”Kusto2023“。</p>
<h2 id="导入数据">导入数据</h2>
<p>有了群集和数据库，接下来就是导入你自己需要的数据了。你可以通过多种方式进行导入，下面我们一一介绍。</p>
<h3 id="从本地数据中导入">从本地数据中导入</h3>
<p>这是初学者最常见的一种方式，谁还没有一点数据在本地计算机呢？虽然Kusto支持很多不同的格式，但用的最多的还是文本文件，而且具体来说就是 <code>csv</code> 文件和 <code>tsv</code> 文件，当然也可以是 <code>json</code> 文件。</p>
<ol>
<li><code>csv</code> 和 <code>tsv</code> 都是用分隔符隔断的文本文件，区别在于 <code>csv</code> 用的是逗号（，），而 <code>tsv</code> 用的是Tab键。 </li>
<li>我个人更喜欢用 <code>csv</code> ，但是 <code>tsv</code> 在某些时候也有奇效，尤其是你的数据字段中包含引号，逗号，空格等字符时。</li>
<li><code>json</code> 格式会给导入带来不必要的麻烦，除非必要，尽量少用。</li>
</ol>
<p>假设现在我们已经有了一个 <code>csv</code> 文件，为了简单起见，我用如下的 Powershell 命令生成了当前我的电脑运行的程序的清单。</p>
<p><code>gps | Export-Csv gps.csv</code></p>
<blockquote>
<p>你可能会经常用到 Export-Csv 这个命令，请参考它的详细说明 <a href="https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/export-csv" target="_blank">https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/export-csv</a> ,  如果是导出 <code>tsv</code>，则这个命令是 <code>gps | Export-Csv gps.tsv -Delimiter</code>t`</p>
</blockquote>
<p>这个文件看起来是下面这样的</p>
<p><img src="../images/Pasted%20image%2020230103053109.png" alt></p>
<p>那么接下来我们就看一下如何将这个文件导入到 Kusto2023 这个数据库吧。你可以通过访问 <a href="https://aka.ms/kustofree" target="_blank">https://aka.ms/kustofree</a> 进入免费群集的首页。</p>
<p><img src="../images/Pasted%20image%2020230103055505.png" alt></p>
<p>点击 ”Ignest“ 这个 按钮，进入下面的界面。</p>
<p><img src="../images/Pasted%20image%2020230103055548.png" alt></p>
<p>设置好Cluster，Database，并选择 New Table选项，输入新的表的名称后点击 ”Next: Source“ 按钮来选择上传的文件。</p>
<p><img src="../images/Pasted%20image%2020230103055722.png" alt></p>
<p>将文件拖放到这个界面，也可以点击 ”Upload files“按钮来选择文件，这里可以选择最多1000个文件。如果一切准备就绪，则点击 ”Next：Scheme“按钮进入下一步。</p>
<p><img src="../images/Pasted%20image%2020230103055944.png" alt></p>
<p>对于一些不甚复杂的文件，这个向导足够聪明，它会自动识别出来文件的格式、是否压缩、以及每个列的数据类型等。当然如果你不满意，也可以修改某些列的类型（但要注意，不恰当的数据类型修改，可能会导致数据丢失）。</p>
<p><img src="../images/Pasted%20image%2020230103060128.png" alt></p>
<p>这个例子演示了如何将 Handles 这个字段的类型从 long 改为 int （点击字段右侧的下拉箭头，选择 <code>Change data type</code> ， 然后选择 <code>int</code> ）， 这样理论上占用的存储空间会小一些。</p>
<p>请留意界面的右侧位置有一个复制按钮，请先点击一下，并且将复制得到的内容放在合适位置，后续的练习会用到。</p>
<p><img src="../images/Pasted%20image%2020230103060524.png" alt></p>
<p>一切准备就绪了，请点击界面上的 ”Next：Start Ingestion“ 按钮开始导入。</p>
<p><img src="../images/Pasted%20image%2020230103060719.png" alt></p>
<p>请等待导入完成后，点击 ”Close“ 按钮关闭当前窗口，进入查询窗口，我们通过如下的查询来验证一下数据。</p>
<pre><code class="lang-kql">Processes
| summarize sum(VM) by Company
| render piechart
</code></pre>
<p><img src="../images/Pasted%20image%2020230103060933.png" alt></p>
<p>这个查询按照应用软件的厂商统计他们占用的内存数和比例。请注意，你那边的数据可能跟我不同，看到的结果也可能不一样。</p>
<p>请注意，你选择的文件其实是要先上传到一个临时的Azure Storage中去，使用完后会自动删除。所以如果你的文件较多，而且体积也不小，建议先做压缩。请注意，这里的压缩不是指你把多个文件直接打包为一个zip文件，这种情况下是无法识别的，你需要直接对单个文件进行压缩，而且需要用 <code>gzip</code> 进行压缩。</p>
<p><code>gzip</code> 不是一个Windows自带的工具，你可以通过<a href="https://gnuwin32.sourceforge.net/packages/gzip.htm" target="_blank">https://gnuwin32.sourceforge.net/packages/gzip.htm</a>  下载得到它。如果你的电脑上安装了 <code>git bash</code> 这个工具，也可以很容易调用它。请参考下面的操作。</p>
<pre><code>gzip gps.csv
</code></pre><p><img src="../images/Pasted%20image%2020230103061913.png" alt></p>
<p>这个命令会生成一个 <code>gps.csv.gz</code> 的文件，原始文件就没有了（也就是说它是就地压缩），而它的体积大致为原文件的 1/6 ，如果你的网络带宽有限，且又需要上传大量的文件，这可能会带来很大的效率提升。</p>
<p><img src="../images/Pasted%20image%2020230103062127.png" alt></p>
<p>还有一个技巧，是可以将这个 gzip 的工具在你常用的PowerShell中定义一个快捷指令，如下所示</p>
<pre><code class="lang-powershell"><span class="hljs-string">&apos;New-Alias gz &quot;C:\Program Files\Git\usr\bin\gzip.exe&quot;&apos;</span> | <span class="hljs-built_in">Out-File</span> <span class="hljs-literal">-Append</span> <span class="hljs-variable">$profile</span>
. <span class="hljs-variable">$profile</span>
</code></pre>
<p>以后就可以很方便地直接运行 <code>gz</code> 命令了。</p>
<h3 id="从azure-blob中导入">从Azure Blob中导入</h3>
<p>从本地文件上传虽然是过瘾的，但大部分时候，你的文件通常不在本地，这些文件可能来自于生产环境的日志，如果要实现从云端导入，目前来说，你需要将他们上传到一个公网可以访问到的地址，最好是Azure Blob Storage 中。</p>
<p>下图是一个例子，我有一个名称叫  <code>chenxizhang</code> 的存储账号（Storage account），然后在里面创建了一个叫 <code>data</code> 的容器（Container），然后我把刚才用到的 <code>gps.csv.gz</code> 这个文件上传到了这个容器。</p>
<p><img src="../images/Pasted%20image%2020230103063746.png" alt></p>
<p>为了能从这个文件进行导入，你需要得到一个可以直接访问它的地址，通常我们的 Container 对外都是无法直接访问的，但你可以为单独的文件生成一个SAS （shared access signature） 地址。</p>
<p><img src="../images/Pasted%20image%2020230103064345.png" alt></p>
<p>点击 ”Generate SAS token and URL“ 按钮后，复制最底部的地址。</p>
<p>那么接下来如何从这个文件导入数据呢？我们还是回到 Azure Data Explorer的 Ingest data 页面。因为此前我们从本地导入过一次，目标表已经创建出来了，所以这一次我们可以选择 ”Existing table“ 这个选项。</p>
<p><img src="../images/Pasted%20image%2020230103064020.png" alt></p>
<p>点击 ”Next：Source“ 按钮， 和之前不同的是，这里选择的 Source type 是 Blob，然后将你刚才复制的SAS 地址粘贴到 Link to source 这个框里面。</p>
<p><img src="../images/Pasted%20image%2020230103064606.png" alt></p>
<p>同样的，这个向导也能自动识别出来文件的格式，是否压缩，然后我们选择 ”Use existing mapping&quot; 这个选项。</p>
<p><img src="../images/Pasted%20image%2020230103064716.png" alt></p>
<blockquote>
<p>如果你的Blob文件本身是可以匿名访问的，则不需要生成SAS 地址。例如范例数据库中的StormEvents这个表，其实它就有一个匿名访问的地址（<a href="https://kustosamples.blob.core.windows.net/samplefiles/StormEvents.csv" target="_blank">https://kustosamples.blob.core.windows.net/samplefiles/StormEvents.csv</a>），你可以试一下。 </p>
</blockquote>
<h3 id="一次性导入多个blob文件">一次性导入多个Blob文件</h3>
<p>刚才我们导入了一个Blob文件，下面看看如何能实现一次性导入多个Blob文件。其实很简单，你只需要把所有的同类文件都放在一个Container下面即可。</p>
<p><img src="../images/Pasted%20image%2020230103073708.png" alt></p>
<p>同样，为了访问这个Container，我们需要为它生成SAS URL。请注意，因为要列出所有的文件，所以在权限这里需要申请 List 的权限。</p>
<p><img src="../images/Pasted%20image%2020230103073802.png" alt></p>
<p>生成这个SAS地址后，你就可以在导入向导页面中，选择Source type 为 Blob container，然后将复制得到的SAS 地址，填入到 Link to source 这个框里面。</p>
<p><img src="../images/Pasted%20image%2020230103073908.png" alt></p>
<p>如果你细心的话， 在 Source type 的下拉列表中，还有一个 ADLS Gen2 Container， 它跟这里介绍的Blob Container没有本质上的不同，只是它是一种更加先进的存储账号类型， ADLS 的意思是 Azure data lake storage， Gen2是指第二代的意思。关于它的介绍，如果你有兴趣，可以参考 <a href="https://learn.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction" target="_blank">https://learn.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction</a> 。 </p>
<h3 id="用控制命令导入数据">用控制命令导入数据</h3>
<p>上面我们都是用图形化界面来实现导入，这本身很好，也不丢人。但如果你需要导入大量的文件，或者需要自动化导入的过程，或你就是一个纯粹地喜欢自己写代码的极客，你可能会想了解所谓的控制命令导入数据的方式。</p>
<p>还记得我之前提醒大家在导入的界面上复制操作命令吗？ 如果你没有忘记保存起来，那么它看起来是像下面这样的。</p>
<pre><code class="lang-kql">// 创建表
////////////////////////////////////////////////////////////
.create table [&apos;Processes&apos;]  ([&apos;Name&apos;]:string, [&apos;SI&apos;]:long, [&apos;Handles&apos;]:long, [&apos;VM&apos;]:long, [&apos;WS&apos;]:long, [&apos;PM&apos;]:long, [&apos;NPM&apos;]:long, [&apos;Path&apos;]:string, [&apos;CommandLine&apos;]:string, [&apos;Parent&apos;]:string, [&apos;Company&apos;]:string, [&apos;CPU&apos;]:real, [&apos;FileVersion&apos;]:string, [&apos;ProductVersion&apos;]:string, [&apos;Description&apos;]:string, [&apos;Product&apos;]:string, [&apos;__NounName&apos;]:string, [&apos;SafeHandle&apos;]:string, [&apos;Handle&apos;]:long, [&apos;BasePriority&apos;]:long, [&apos;ExitCode&apos;]:string, [&apos;HasExited&apos;]:bool, [&apos;StartTime&apos;]:datetime, [&apos;ExitTime&apos;]:string, [&apos;Id&apos;]:long, [&apos;MachineName&apos;]:string, [&apos;MaxWorkingSet&apos;]:long, [&apos;MinWorkingSet&apos;]:long, [&apos;Modules&apos;]:string, [&apos;NonpagedSystemMemorySize64&apos;]:long, [&apos;NonpagedSystemMemorySize&apos;]:long, [&apos;PagedMemorySize64&apos;]:long, [&apos;PagedMemorySize&apos;]:long, [&apos;PagedSystemMemorySize64&apos;]:long, [&apos;PagedSystemMemorySize&apos;]:long, [&apos;PeakPagedMemorySize64&apos;]:long, [&apos;PeakPagedMemorySize&apos;]:long, [&apos;PeakWorkingSet64&apos;]:long, [&apos;PeakWorkingSet&apos;]:long, [&apos;PeakVirtualMemorySize64&apos;]:long, [&apos;PeakVirtualMemorySize&apos;]:long, [&apos;PriorityBoostEnabled&apos;]:bool, [&apos;PriorityClass&apos;]:string, [&apos;PrivateMemorySize64&apos;]:long, [&apos;PrivateMemorySize&apos;]:long, [&apos;ProcessorAffinity&apos;]:long, [&apos;SessionId&apos;]:long, [&apos;StartInfo&apos;]:string, [&apos;Threads&apos;]:string, [&apos;HandleCount&apos;]:long, [&apos;VirtualMemorySize64&apos;]:long, [&apos;VirtualMemorySize&apos;]:long, [&apos;EnableRaisingEvents&apos;]:bool, [&apos;StandardInput&apos;]:string, [&apos;StandardOutput&apos;]:string, [&apos;StandardError&apos;]:string, [&apos;WorkingSet64&apos;]:long, [&apos;WorkingSet&apos;]:long, [&apos;SynchronizingObject&apos;]:string, [&apos;MainModule&apos;]:string, [&apos;PrivilegedProcessorTime&apos;]:timespan, [&apos;TotalProcessorTime&apos;]:timespan, [&apos;UserProcessorTime&apos;]:timespan, [&apos;ProcessName&apos;]:string, [&apos;MainWindowHandle&apos;]:long, [&apos;MainWindowTitle&apos;]:string, [&apos;Responding&apos;]:bool, [&apos;Site&apos;]:string, [&apos;Container&apos;]:string)

// 创建字段映射
////////////////////////////////////////////////////////////
.create table [&apos;Processes&apos;] ingestion csv mapping &apos;Processes_mapping&apos; &apos;[{&quot;column&quot;:&quot;Name&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;0&quot;}},{&quot;column&quot;:&quot;SI&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;1&quot;}},{&quot;column&quot;:&quot;Handles&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;2&quot;}},{&quot;column&quot;:&quot;VM&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;3&quot;}},{&quot;column&quot;:&quot;WS&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;4&quot;}},{&quot;column&quot;:&quot;PM&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;5&quot;}},{&quot;column&quot;:&quot;NPM&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;6&quot;}},{&quot;column&quot;:&quot;Path&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;7&quot;}},{&quot;column&quot;:&quot;CommandLine&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;8&quot;}},{&quot;column&quot;:&quot;Parent&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;9&quot;}},{&quot;column&quot;:&quot;Company&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;10&quot;}},{&quot;column&quot;:&quot;CPU&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;11&quot;}},{&quot;column&quot;:&quot;FileVersion&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;12&quot;}},{&quot;column&quot;:&quot;ProductVersion&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;13&quot;}},{&quot;column&quot;:&quot;Description&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;14&quot;}},{&quot;column&quot;:&quot;Product&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;15&quot;}},{&quot;column&quot;:&quot;__NounName&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;16&quot;}},{&quot;column&quot;:&quot;SafeHandle&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;17&quot;}},{&quot;column&quot;:&quot;Handle&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;18&quot;}},{&quot;column&quot;:&quot;BasePriority&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;19&quot;}},{&quot;column&quot;:&quot;ExitCode&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;20&quot;}},{&quot;column&quot;:&quot;HasExited&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;21&quot;}},{&quot;column&quot;:&quot;StartTime&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;22&quot;}},{&quot;column&quot;:&quot;ExitTime&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;23&quot;}},{&quot;column&quot;:&quot;Id&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;24&quot;}},{&quot;column&quot;:&quot;MachineName&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;25&quot;}},{&quot;column&quot;:&quot;MaxWorkingSet&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;26&quot;}},{&quot;column&quot;:&quot;MinWorkingSet&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;27&quot;}},{&quot;column&quot;:&quot;Modules&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;28&quot;}},{&quot;column&quot;:&quot;NonpagedSystemMemorySize64&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;29&quot;}},{&quot;column&quot;:&quot;NonpagedSystemMemorySize&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;30&quot;}},{&quot;column&quot;:&quot;PagedMemorySize64&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;31&quot;}},{&quot;column&quot;:&quot;PagedMemorySize&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;32&quot;}},{&quot;column&quot;:&quot;PagedSystemMemorySize64&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;33&quot;}},{&quot;column&quot;:&quot;PagedSystemMemorySize&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;34&quot;}},{&quot;column&quot;:&quot;PeakPagedMemorySize64&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;35&quot;}},{&quot;column&quot;:&quot;PeakPagedMemorySize&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;36&quot;}},{&quot;column&quot;:&quot;PeakWorkingSet64&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;37&quot;}},{&quot;column&quot;:&quot;PeakWorkingSet&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;38&quot;}},{&quot;column&quot;:&quot;PeakVirtualMemorySize64&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;39&quot;}},{&quot;column&quot;:&quot;PeakVirtualMemorySize&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;40&quot;}},{&quot;column&quot;:&quot;PriorityBoostEnabled&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;41&quot;}},{&quot;column&quot;:&quot;PriorityClass&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;42&quot;}},{&quot;column&quot;:&quot;PrivateMemorySize64&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;43&quot;}},{&quot;column&quot;:&quot;PrivateMemorySize&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;44&quot;}},{&quot;column&quot;:&quot;ProcessorAffinity&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;45&quot;}},{&quot;column&quot;:&quot;SessionId&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;46&quot;}},{&quot;column&quot;:&quot;StartInfo&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;47&quot;}},{&quot;column&quot;:&quot;Threads&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;48&quot;}},{&quot;column&quot;:&quot;HandleCount&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;49&quot;}},{&quot;column&quot;:&quot;VirtualMemorySize64&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;50&quot;}},{&quot;column&quot;:&quot;VirtualMemorySize&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;51&quot;}},{&quot;column&quot;:&quot;EnableRaisingEvents&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;52&quot;}},{&quot;column&quot;:&quot;StandardInput&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;53&quot;}},{&quot;column&quot;:&quot;StandardOutput&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;54&quot;}},{&quot;column&quot;:&quot;StandardError&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;55&quot;}},{&quot;column&quot;:&quot;WorkingSet64&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;56&quot;}},{&quot;column&quot;:&quot;WorkingSet&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;57&quot;}},{&quot;column&quot;:&quot;SynchronizingObject&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;58&quot;}},{&quot;column&quot;:&quot;MainModule&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;59&quot;}},{&quot;column&quot;:&quot;PrivilegedProcessorTime&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;60&quot;}},{&quot;column&quot;:&quot;TotalProcessorTime&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;61&quot;}},{&quot;column&quot;:&quot;UserProcessorTime&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;62&quot;}},{&quot;column&quot;:&quot;ProcessName&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;63&quot;}},{&quot;column&quot;:&quot;MainWindowHandle&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;64&quot;}},{&quot;column&quot;:&quot;MainWindowTitle&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;65&quot;}},{&quot;column&quot;:&quot;Responding&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;66&quot;}},{&quot;column&quot;:&quot;Site&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;67&quot;}},{&quot;column&quot;:&quot;Container&quot;, &quot;Properties&quot;:{&quot;Ordinal&quot;:&quot;68&quot;}}]&apos;

// 导入数据
///////////////////////////////////////////////////////////
.ingest async into table [&apos;Processes&apos;] (h&apos;&lt;blob path to upload&gt;&apos;) with (format=&apos;csv&apos;,ingestionMappingReference=&apos;Processes_mapping&apos;,ingestionMappingType=&apos;csv&apos;,tags=&quot;[&apos;fa331bbd-c940-4630-8c2e-d5b20ec304dc&apos;]&quot;,ignoreFirstRecord=true)
</code></pre>
<p>第一步（创建表）和第二步（创建映射）并不是每次都需要执行，而第三步（导入数据），其实你要替换的就是 <code>&lt;blob path to upload&gt;</code>  这里的信息就可以了。</p>
<p>当然，要用这个脚本来执行，你的文件必须已经放到了云端，并且生成了SAS 地址。</p>
<p>这里其实还有一个小技巧。大家有没有发现，上面这一大堆代码中，其实占据主要部分的是创建表结构和映射，当表的字段不是很多时，这并不难，但如果字段超过十个，你就会觉得手工写那些字段名和他们的数据类型，会很吃力。那么有没有一种办法从一个外部文件自动得到表结构，并且用于来创建表呢？</p>
<p>下面我们看看如何根据一个容器，自动生成表结构，并且用几行简单的命令来实现导入吧。</p>
<pre><code>let options = dynamic({
  &apos;StorageContainers&apos;: [
    h@&apos;https://chenxizhang.blob.core.windows.net/data?sp=rl&amp;st=2023-01-02T23:37:45Z&amp;se=2023-01-03T07:37:45Z&amp;spr=https&amp;sv=2021-06-08&amp;sr=c&amp;sig=439I73xNeFPsAtrXKFVJlLC3cnFGqoZeCrkRi6eFy6w%3D&apos;
  ],

  &apos;FileExtension&apos;: &apos;.csv.gz&apos;,
  &apos;DataFormat&apos;: &apos;csv&apos;

});

evaluate infer_storage_schema(options)
</code></pre><p>这个查询使用了一个插件（<code>infer_storage_schema</code>），它返回的结果只有一个字段，它包含所有字段的定义，并且用一个字符串表示，你可以用它来快速创建你的表了。</p>
<p><img src="../images/Pasted%20image%2020230103080215.png" alt></p>
<h3 id="从其他数据库中导入">从其他数据库中导入</h3>
<p>除了从文件中导入数据，另外一种经常用的方式是从别的数据库中复制数据，这个数据可以是原始数据，也可以是聚合过之后的计算结果。</p>
<p>假设我们现在想把范例数据库中的 StormEvents 表完整地复制到自己的数据库，你可以尝试下面的查询。</p>
<pre><code>.set-or-append StormEvents &lt;|
    cluster(&apos;help&apos;).database(&apos;Samples&apos;).StormEvents
</code></pre><p><code>.set-or-append</code> 是一个控制命令，我们不在这一季中过多地展开，只是在用到时就用一下。这个命令的意思是创建新表或者向现有表追加数据。这个命令的好处是连创建表的语法都不需要了。</p>
<p><code>&lt;|</code> 这个指令是指把后面查询的结果，输出到前面的目标表。目标表可以是同一个数据库，也可以是其他数据库，甚至其他群集。</p>
<p>下面再来看一个更加复杂一点的，把计算结果追加到目标表中。</p>
<pre><code class="lang-kql">.set-or-append StateSummarization &lt;|
    cluster(&apos;help&apos;).database(&apos;Samples&apos;).StormEvents
    | summarize
        count = count(),
        crops = sum(DamageCrops),
        property= sum(DamageProperty)
        by
        State,
        bin(StartTime, 1d)
</code></pre>
<p>其实认真说起来，除了行数多一点之外，这个查询也没有什么复杂的。</p>
<p><img src="../images/Pasted%20image%2020230103081859.png" alt></p>
<h2 id="导出数据">导出数据</h2>
<p>本章的最后我们研究一下如何在需要时将查询的数据导出，包括导出到本地csv文件，以及导出到云端的Blob文件。</p>
<h3 id="导出本地csv文件">导出本地csv文件</h3>
<p>要导出你的数据，你只需要编写好查询，然后确定得到了你想要的数据，最后在工具栏中点击 “File”下拉菜单中的 “Export to CSV” 即可。</p>
<p><img src="../images/Pasted%20image%2020230103082347.png" alt></p>
<blockquote>
<p>📣要执行这个操作，还有一个快捷方式，就是先按下 F1 键，呼唤出命令窗口，然后输入 export，回车即可。</p>
</blockquote>
<p>如果你使用本地的 Kusto.explorer 这个工具，则导出的选项会多一点，但说实话，导出csv 是最常见的了。</p>
<p><img src="../images/Pasted%20image%2020230103083041.png" alt></p>
<h3 id="导出到blob文件">导出到Blob文件</h3>
<p>那么，如果我想把查询结果导出到云端呢？首先你需要准备一个容器（Container），并且生成一个包含了 <code>Write</code> 权限的SAS URL。</p>
<p><img src="../images/Pasted%20image%2020230103083812.png" alt></p>
<pre><code>.export async compressed to csv
    (h&apos;https://chenxizhang.blob.core.windows.net/data?sp=rw&amp;st=2023-01-02T23:37:45Z&amp;se=2023-01-03T07:37:45Z&amp;spr=https&amp;sv=2021-06-08&amp;sr=c&amp;sig=pxWNDEcr2tMzkXOp8iY%2F0RuZ8mLOsLUmJbyJq5kpn6A%3D&apos;)  
    with (includeHeaders=&apos;all&apos;)   &lt;|
    StormEvents
    | summarize
        count = count(),
        crops = sum(DamageCrops),
        property= sum(DamageProperty)
        by
        State,
        bin(StartTime, 1d)
</code></pre><p>执行这个命令会在目标的容器中生成一个随机的文件（以.csv.gz 为扩展名），你甚至还可以为一个查询生成多个文件（即按一定的大小自动拆分文件），只要设置 sizeLimit 的选项值就可以了（以字节为单位）。</p>
<pre><code>.export async compressed to csv
    (h&apos;https://chenxizhang.blob.core.windows.net/data?sp=rw&amp;st=2023-01-02T23:37:45Z&amp;se=2023-01-03T07:37:45Z&amp;spr=https&amp;sv=2021-06-08&amp;sr=c&amp;sig=pxWNDEcr2tMzkXOp8iY%2F0RuZ8mLOsLUmJbyJq5kpn6A%3D&apos;)  
    with (
    includeHeaders=&apos;all&apos;,
    sizeLimit =100000
    )   &lt;|
    StormEvents
    | summarize
        count = count(),
        crops = sum(DamageCrops),
        property= sum(DamageProperty)
        by
        State,
        bin(StartTime, 1d)
</code></pre><p>文件名并不重要，因为如果你以后导入时，其实也不需要知道具体的文件名，只要通过容器导入即可。这真是太强大了。</p>
<p><img src="../images/Pasted%20image%2020230103084251.png" alt></p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="chapter3.html" class="navigation navigation-prev " aria-label="Previous page: 第三章：数据可视化">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="chapter5.html" class="navigation navigation-next " aria-label="Next page: 第五章：外部应用集成">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"第四章：数据导入和导出","level":"1.3.4","depth":2,"next":{"title":"第五章：外部应用集成","level":"1.3.5","depth":2,"path":"part1/chapter5.md","ref":"part1/chapter5.md","articles":[]},"previous":{"title":"第三章：数据可视化","level":"1.3.3","depth":2,"path":"part1/chapter3.md","ref":"part1/chapter3.md","articles":[]},"dir":"ltr"},"config":{"plugins":["honkit-plugin-google-analytics"],"root":"docs","styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"analytics":{"uid":"G-PCF513CZTS"},"honkit-plugin-google-analytics":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","author":"陈希章","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56},"embedFonts":false},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"大数据分析新玩法之Kusto宝典","language":"zh","gitbook":"*","description":"大数据分析，Kusto，Azure Data Explorer"},"file":{"path":"part1/chapter4.md","mtime":"2023-01-07T02:16:52.210Z","type":"markdown"},"gitbook":{"version":"3.7.5","time":"2023-01-07T02:17:03.544Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <noscript>
        <style>
            .honkit-cloak {
                display: block !important;
            }
        </style>
    </noscript>
    <script>
        // Restore sidebar state as critical path for prevent layout shift
        function __init__getSidebarState(defaultValue){
            var baseKey = "";
            var key = baseKey + ":sidebar";
            try {
                var value = localStorage[key];
                if (value === undefined) {
                    return defaultValue;
                }
                var parsed = JSON.parse(value);
                return parsed == null ? defaultValue : parsed;
            } catch (e) {
                return defaultValue;
            }
        }
        function __init__restoreLastSidebarState() {
            var isMobile = window.matchMedia("(max-width: 600px)").matches;
            if (isMobile) {
                // Init last state if not mobile
                return;
            }
            var sidebarState = __init__getSidebarState(true);
            var book = document.querySelector(".book");
            // Show sidebar if it enabled
            if (sidebarState && book) {
                book.classList.add("without-animation", "with-summary");
            }
        }

        try {
            __init__restoreLastSidebarState();
        } finally {
            var book = document.querySelector(".book");
            book.classList.remove("honkit-cloak");
        }
    </script>
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

